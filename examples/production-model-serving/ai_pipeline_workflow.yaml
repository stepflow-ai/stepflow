schema: https://stepflow.org/schemas/v1/flow.json
name: Production AI Pipeline
description: 'Demonstrates production-ready AI model serving with:

  1. Resource-aware model routing (CPU vs GPU models)

  2. Health checks and monitoring

  3. Batch processing for efficiency

  4. Multi-modal AI processing (text + vision)


  This workflow showcases how Stepflow enables:

  - Independent scaling of different model types

  - Resource optimization through intelligent routing

  - Production monitoring and observability

  - Graceful error handling and fallbacks

  '
schemas:
  type: object
  properties:
    input:
      type: object
      properties:
        user_text:
          type: string
          description: Text content to analyze
        user_image:
          type: string
          description: Base64 encoded image to classify
        processing_mode:
          type: string
          enum:
          - fast
          - accurate
          - batch
          default: fast
        batch_size:
          type: integer
          default: 4
          description: Batch size for processing
        prefer_gpu:
          type: boolean
          default: false
          description: Prefer GPU models when available
      required:
      - user_text
    output:
      type: object
      properties:
        processing_summary:
          type: object
        text_analysis:
          type: object
        image_analysis:
          type: object
steps:
- id: text_health_check
  component: /models/text/model_health_check
  input:
    detailed: true
  on_error:
    action: fail
    message: Text model server unavailable
- id: vision_health_check
  component: /models/vision/vision_health_check
  input:
    detailed: true
  on_error:
    action: skip
- id: processing_config_udf
  component: /put_blob
  input:
    data:
      input_schema:
        type: object
        properties:
          prefer_gpu:
            type: boolean
          processing_mode:
            type: string
      code: "return {\n    \"prefer_gpu\": input.prefer_gpu,\n    \"processing_mode\"\
        : input.processing_mode,\n    \"suggested_text_model\": \"distilbert-sentiment\"\
        ,\n}\n"
    blob_type: data
- id: processing_config
  component: /python/udf
  input:
    blob_id:
      $step: processing_config_udf
      path: blob_id
    input:
      prefer_gpu:
        $input: prefer_gpu
      processing_mode:
        $input: processing_mode
- id: sentiment_analysis_udf
  component: /put_blob
  input:
    data:
      input_schema:
        type: object
        properties:
          user_text:
            type: string
          suggested_text_model:
            type: string
      code: "if not input.user_text or len(input.user_text.strip()) == 0:\n    raise\
        \ SkipStep(\"No text provided for sentiment analysis\")\n\n# Return the configuration\
        \ for the actual sentiment analysis step\nreturn {\n    \"text\": input.user_text,\n\
        \    \"model_name\": input.suggested_text_model\n}\n"
    blob_type: data
- id: sentiment_analysis_config
  component: /python/udf
  input:
    blob_id:
      $step: sentiment_analysis_udf
      path: blob_id
    input:
      user_text:
        $input: user_text
      suggested_text_model:
        $step: processing_config
        path: suggested_text_model
- id: sentiment_analysis
  component: /models/text/analyze_sentiment
  input:
    text:
      $step: sentiment_analysis_config
      path: text
    model_name:
      $step: sentiment_analysis_config
      path: model_name
- id: text_generation_udf
  component: /put_blob
  input:
    data:
      input_schema:
        type: object
        properties:
          processing_mode:
            type: string
          user_text:
            type: string
          sentiment_analysis:
            type: object
      code: "if input.processing_mode != \"fast\":\n    raise SkipStep(\"Text generation\
        \ only runs in fast processing mode\")\n\n# Build the prompt with sentiment\
        \ context\nsentiment = input.sentiment_analysis\nprompt = f\"Based on the\
        \ sentiment analysis ({sentiment['label']} with confidence {sentiment['score']}),\
        \ generate a thoughtful response to: {input.user_text}\"\n\nreturn {\n   \
        \ \"prompt\": prompt,\n    \"model_name\": \"gpt2-small\",\n    \"max_length\"\
        : 150,\n    \"temperature\": 0.7\n}\n"
    blob_type: data
- id: text_generation_config
  component: /python/udf
  input:
    blob_id:
      $step: text_generation_udf
      path: blob_id
    input:
      processing_mode:
        $step: processing_config
        path: processing_mode
      user_text:
        $input: user_text
      sentiment_analysis:
        $step: sentiment_analysis
- id: text_generation
  component: /models/text/generate_text
  input:
    prompt:
      $step: text_generation_config
      path: prompt
    model_name:
      $step: text_generation_config
      path: model_name
    max_length:
      $step: text_generation_config
      path: max_length
    temperature:
      $step: text_generation_config
      path: temperature
- id: image_classification_udf
  component: /put_blob
  input:
    data:
      input_schema:
        type: object
        properties:
          user_image:
            type: string
      code: "image_data = input.get(\"user_image\", \"\") or \"\"\nif not image_data\
        \ or len(image_data.strip()) == 0:\n    raise SkipStep(\"No image provided\
        \ for classification\")\n\nreturn {\n    \"image_data\": image_data,\n   \
        \ \"model_name\": \"resnet50\",  # Default vision model\n    \"top_k\": 5\n\
        }\n"
    blob_type: data
- id: image_classification_config
  component: /python/udf
  input:
    blob_id:
      $step: image_classification_udf
      path: blob_id
    input:
      user_image:
        $input: user_image
- id: image_classification
  component: /models/vision/classify_image
  input:
    image_data:
      $step: image_classification_config
      path: image_data
    model_name:
      $step: image_classification_config
      path: model_name
    top_k:
      $step: image_classification_config
      path: top_k
  on_error:
    action: skip
    message: Image processing failed, continuing without image analysis
- id: image_analysis_udf
  component: /put_blob
  input:
    data:
      input_schema:
        type: object
        properties:
          user_image:
            type: string
      code: "image_data = input.get(\"user_image\", \"\") or \"\"\nif not image_data\
        \ or len(image_data.strip()) == 0:\n    raise SkipStep(\"No image provided\
        \ for metrics analysis\")\n\nreturn {\"image_data\": image_data}\n"
    blob_type: data
- id: image_analysis_config
  component: /python/udf
  input:
    blob_id:
      $step: image_analysis_udf
      path: blob_id
    input:
      user_image:
        $input: user_image
- id: image_analysis
  component: /models/vision/analyze_image_metrics
  input:
    image_data:
      $step: image_analysis_config
      path: image_data
- id: batch_demo_udf
  component: /put_blob
  input:
    data:
      input_schema:
        type: object
        properties:
          processing_mode:
            type: string
          user_text:
            type: string
          batch_size:
            type: integer
      code: "if input.processing_mode != \"batch\":\n    raise SkipStep(\"Batch processing\
        \ only runs in batch processing mode\")\n\nreturn {\n    \"texts\": [\n  \
        \      input.user_text,\n        \"Additional sample text for batch processing\"\
        ,\n        \"Another example to show batching efficiency\"\n    ],\n    \"\
        model_name\": \"distilbert-sentiment\",\n    \"task\": \"sentiment\",\n  \
        \  \"batch_size\": input.batch_size\n}\n"
    blob_type: data
- id: batch_demo_config
  component: /python/udf
  input:
    blob_id:
      $step: batch_demo_udf
      path: blob_id
    input:
      processing_mode:
        $step: processing_config
        path: processing_mode
      user_text:
        $input: user_text
      batch_size:
        $input: batch_size
- id: batch_demo
  component: /models/text/batch_process_text
  input:
    texts:
      $step: batch_demo_config
      path: texts
    model_name:
      $step: batch_demo_config
      path: model_name
    task:
      $step: batch_demo_config
      path: task
    batch_size:
      $step: batch_demo_config
      path: batch_size
- id: final_results_udf
  component: /put_blob
  input:
    data:
      input_schema:
        type: object
        properties:
          processing_config:
            type: object
          sentiment_analysis:
            type: object
          text_generation:
            type: object
          image_classification:
            type: object
          image_analysis:
            type: object
          batch_demo:
            type: object
      code: "processing_config = input.get(\"processing_config\", {})\nsentiment_analysis\
        \ = input.get(\"sentiment_analysis\", None)\ntext_generation = input.get(\"\
        text_generation\", None)\nimage_classification = input.get(\"image_classification\"\
        , None)\nimage_analysis = input.get(\"image_analysis\", None)\nbatch_demo\
        \ = input.get(\"batch_demo\", None)\n\nreturn {\n  \"processing_summary\"\
        : {\n    \"mode\": processing_config.get(\"processing_mode\", \"unknown\"\
        ),\n    \"text_processed\": sentiment_analysis is not None,\n    \"image_processed\"\
        : image_classification is not None,\n    \"batch_processing_used\": batch_demo\
        \ is not None,\n    \"total_processing_time_ms\": (\n      (sentiment_analysis.get(\"\
        inference_time\", {}).get(\"ms\", 0) if sentiment_analysis else 0) +\n   \
        \   (text_generation.get(\"generation_time_ms\", 0) if text_generation else\
        \ 0) +\n      (image_classification.get(\"inference_time_ms\", 0) if image_classification\
        \ else 0)\n    )\n  },\n  \"text_analysis\": {\n    \"sentiment\": sentiment_analysis.get(\"\
        label\") if sentiment_analysis else None,\n    \"confidence\": sentiment_analysis.get(\"\
        score\") if sentiment_analysis else None,\n    \"model_used\": sentiment_analysis.get(\"\
        model_used\") if sentiment_analysis else None,\n    \"generated_response\"\
        : text_generation.get(\"generated_text\") if text_generation else None\n \
        \ },\n  \"image_analysis\": {\n    \"classifications\": image_classification.get(\"\
        predictions\") if image_classification else None,\n    \"image_properties\"\
        : {\n      \"dimensions\": [image_analysis.get(\"width\", 0), image_analysis.get(\"\
        height\", 0)],\n      \"format\": image_analysis.get(\"format\"),\n      \"\
        size_bytes\": image_analysis.get(\"size_bytes\"),\n      \"recommended_model\"\
        : image_analysis.get(\"recommended_model\")\n    } if image_analysis else\
        \ None,\n    \"resource_tier_used\": image_classification.get(\"resource_tier\"\
        ) if image_classification else None\n  },\n}\n"
    blob_type: data
- id: final_results
  component: /python/udf
  input:
    blob_id:
      $step: final_results_udf
      path: blob_id
    input:
      processing_config:
        $step: processing_config
      sentiment_analysis:
        $step: sentiment_analysis
      batch_demo:
        $step: batch_demo
      text_generation:
        $step: text_generation
      image_classification:
        $step: image_classification
      image_analysis:
        $step: image_analysis
output:
  $step: final_results
